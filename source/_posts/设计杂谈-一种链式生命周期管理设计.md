---
title: '设计杂谈:一种链式生命周期管理设计'
date: 2017-04-06 22:16:19
tags:
  - 设计
  - 技术
  - 杂谈
---

　　最近在了解大数据及机器学习相关的技术，在看到一张关于hadoop的hdfs的写数据过程的流程图之后，发现hdfs在分布式集群上写数据的过程设计，和我之前设计的一个流程引擎的一个流程生命周期有很大的相似之处，因此今天拿出来分享一下。
<!-- more -->
　　先来看看hdfs在分布式是怎么写数据的：


![](/img/hdfs-write.jpg)

　　这里不讲hadoop的相关技术，忽略其他细节，大致就是由集群的master（名称节点）开始一个写数据的流程，由这个节点决定这个数据要往哪些机器上写，分别写什么部分，但是这个master并不是分成多份数据直接发送到不同的机器上，执行写数据的命令。而是进行流式写入，先将数据发送到第一台机器，第一台机器写完之后由第一台机器发往第二台机器，依次类推，知道最后一台机器将数据写完，又进行节点回调，告诉倒数第二台机器数据写完，倒数第二台收到后，告诉倒数第三台机器数据写完的消息，依次回调到master主机上。

　　在hdfs的设计理念上，这样的做法确实是最合适的，因为所有的数据请求都需要通过名称节点（master）来处理，如果这样的分布式数据存储消息都要由master来处理的话，随着集群规模的扩大，数据请求数量变得庞大，master节点必然处理起来会非常乏力，可能出现cpu爆满，甚至宕机的情况。这样做的坏处也是有的，最明显的就是花费了更多的网络带宽（当然一般集群都是局域网的），因此这样也无伤大雅。

　　那么说完这个之后，先来看看我之前的基础设计是怎样的：

![](/img/step-class-diagram.jpg)

　　这个设计其实很简单，Step接口定义了两个接口，分别是stepBegin()和stepEnd()，分别来处理流程节点事务和流程结束的回调处理，整个流程的生命周期由代理类StepNode来管理，StepNode有聚合实现了Step接口的具体流程节点类，并确定好节点之间的次序关系。如下图：

![](/img/step-progress.jpg)

　　图中的1、2、3、4步骤代表四个流程节点的事务处理操作，即stepBegin(),图中的5、6、7、8步骤代表流程结束后各个节点的回调处理操作，即stepEnd()。

这样设计的好处是：整个流程的生命周期都在可控的范围之内，非常容易管理到每一个节点，并且每个节点都能清楚的知道其所依赖的前后节点的执行状况，并且通过上下文参数来传递可用的信息，同时流程节点也十分容易扩展，可扩展的面非常广，应用的面也非常。

PS:当然，具体的项目应用肯定不仅仅是上面的类图设计的那么简单，但是思想是一样的，设计的理念是一样的，只是不同的应用实现可以做不同的扩展、优化。

PS2：一个好的设计来源于适合的应用场景，有一个很著名的话是这样讲的：

> 美不是来自于创造，没来自于选择。

我对这句话在程序员的角度理解：
> 好的设计不是来自于遐想，来自于选择对的应用场景。
